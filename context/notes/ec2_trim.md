1Ô∏è‚É£ Clean system logs (safe + high ROI)
Check log size
sudo du -sh /var/log/*

Vacuum old systemd logs
sudo journalctl --disk-usage
sudo journalctl --vacuum-time=7d


What this does

Deletes system logs older than 7 days

Frees root disk

Safe on production servers

(Optional stricter)

sudo journalctl --vacuum-size=200M

2Ô∏è‚É£ Truncate Docker logs (VERY important)

Docker logs are a silent disk killer.

Find big containers
sudo du -sh /var/lib/docker/containers/*/*-json.log

Truncate all Docker logs (safe)
sudo find /var/lib/docker/containers/ -name "*-json.log" -exec truncate -s 0 {} \;


What this does

Keeps containers running

Resets log files to 0 bytes

No downtime

3Ô∏è‚É£ Docker cleanup (images, layers, stopped containers)
See Docker usage
docker system df

Remove unused containers, images, networks
docker system prune -f

More aggressive (optional)
docker system prune -a -f


What this does

Removes:

stopped containers

unused images

dangling volumes

Does NOT touch running containers

4Ô∏è‚É£ APT package cache cleanup

Ubuntu keeps old packages around.

sudo apt autoremove -y
sudo apt autoclean


What this does

Removes unused dependencies

Clears old .deb packages

Frees root disk

5Ô∏è‚É£ ClickHouse-specific cleanup (CRITICAL)
Check ClickHouse disk usage
sudo du -sh /mnt/clickhouse/*

Remove old ClickHouse logs
sudo du -sh /var/log/clickhouse-server
sudo truncate -s 0 /var/log/clickhouse-server/*.log


Safe ‚Äî ClickHouse will continue logging.

Optional but VERY useful: TTL-based cleanup (long-term)

If you are storing raw orderbook events, you should not keep them forever on hot disk.

Example (adjust days):

ALTER TABLE orderbook_events
MODIFY TTL ts + INTERVAL 30 DAY;


What this does

Automatically deletes data older than 30 days

Prevents silent disk death

Essential for streaming systems

6Ô∏è‚É£ Find large files anywhere (diagnostics)
sudo du -ah / | sort -rh | head -40


What this does

Lists the 40 largest files/directories

Use this when disk grows unexpectedly

7Ô∏è‚É£ Set log rotation (so this never happens again)
Docker log limits (recommended)

Edit or create:

sudo nano /etc/docker/daemon.json


Add:

{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "50m",
    "max-file": "3"
  }
}


Restart Docker:

sudo systemctl restart docker

System log retention

Edit:

sudo nano /etc/systemd/journald.conf


Set:

SystemMaxUse=200M
MaxRetentionSec=7day


Restart:

sudo systemctl restart systemd-journald

8Ô∏è‚É£ Create a monthly ‚Äúmaintenance command‚Äù (copy/paste)

Save this as ~/maintenance.sh:

#!/bin/bash
set -e

echo "üßπ Cleaning system logs..."
sudo journalctl --vacuum-time=7d

echo "üê≥ Truncating Docker logs..."
sudo find /var/lib/docker/containers/ -name "*-json.log" -exec truncate -s 0 {} \;

echo "üê≥ Docker prune..."
docker system prune -f

echo "üì¶ Cleaning apt cache..."
sudo apt autoremove -y
sudo apt autoclean

echo "üìä Disk usage:"
df -h


Run monthly:

chmod +x ~/maintenance.sh
./maintenance.sh

9Ô∏è‚É£ What I‚Äôd recommend next (for your setup)

Given:

ClickHouse

Streaming data

Docker

EC2

You should strongly consider:

Increasing /mnt/clickhouse to 50‚Äì100G

TTL rules for all raw tables

Daily monitoring:

watch -n 60 df -h


Cold storage (Parquet ‚Üí S3) for historical data